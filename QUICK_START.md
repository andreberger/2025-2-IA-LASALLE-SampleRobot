# ğŸš€ Guia de InÃ­cio RÃ¡pido - Collision Avoidance Neural

## âš¡ Setup em 5 Minutos

### 1. PrÃ©-requisitos
```bash
# Verifique se tem instalado:
g++ --version      # Deve ser g++ 5.0 ou superior
MobileSim          # Simulador do robÃ´
```

### 2. Clone e Compile
```bash
cd /seu/diretorio/de/trabalho
git clone [seu-fork-url]
cd 2025-2-IA-LASALLE-SampleRobot
make
```

### 3. Treine a Rede (IMPORTANTE!)
```bash
# Isso vai criar o arquivo trained_weights.json
./build/train_network
```

Aguarde a mensagem:
```
âœ“ ConvergÃªncia alcanÃ§ada na Ã©poca XXXXX
âœ“ Modelo treinado salvo com sucesso!
```

### 4. Execute o RobÃ´
```bash
# Terminal 1: Inicie o simulador
MobileSim

# Terminal 2: Execute o robÃ´
./build/main trained_weights.json
```

Pronto! O robÃ´ agora navega usando rede neural! ğŸ‰

---

## ğŸ¯ Para a ApresentaÃ§Ã£o Final

### Checklist Antes da ApresentaÃ§Ã£o

- [ ] **Compilar tudo**: `make clean && make`
- [ ] **Treinar rede**: `./build/train_network` (salva pesos)
- [ ] **Testar execuÃ§Ã£o**: `./build/main trained_weights.json`
- [ ] **MobileSim rodando**: Mapa definido pelo professor
- [ ] **CÃ³digo comentado**: Todos arquivos com documentaÃ§Ã£o
- [ ] **Git log limpo**: Commits de todos membros visÃ­veis

### Comandos Ãšteis

```bash
# Ver ajuda do Makefile
make help

# Compilar apenas treinamento
make train

# Compilar apenas robÃ´
make robot

# Limpar e recompilar tudo
make clean && make all

# Ver commits de cada membro
git log --author="Nome" --oneline
```

---

## ğŸ› Troubleshooting

### Erro: "cannot find -lAria"
```bash
# Reinstale ARIA
sudo dpkg -i libaria_2.9.4+ubuntu16_amd64.deb
```

### Erro: "Connection refused"
```bash
# Certifique-se que MobileSim estÃ¡ rodando
ps aux | grep MobileSim

# Se nÃ£o estiver, inicie:
MobileSim &
```

### Rede nÃ£o converge
```bash
# Aumente o nÃºmero de Ã©pocas em train_network.cpp
# Linha ~XXX: trainBatch(..., 200000, ...)  // Era 100000
```

### RobÃ´ colide
```bash
# Verifique se carregou pesos treinados:
./build/main trained_weights.json

# Se nÃ£o existir, treine primeiro:
./build/train_network
```

---

## ğŸ“Š Exemplo de SaÃ­da Esperada

### Treinamento
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘   TREINAMENTO DA REDE NEURAL                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Criando arquitetura da rede neural...
Arquitetura da rede:
  Entrada: 4 neurÃ´nios
  Oculta 1: 5 neurÃ´nios (Sigmoid)
  SaÃ­da:   1 neurÃ´nios (Sigmoid)
  Taxa de aprendizado: 0.3
  Momentum: 0.9

========================================
INICIANDO TREINAMENTO
========================================
Ã‰poca      1 | Erro mÃ©dio: 0.142567
Ã‰poca   1000 | Erro mÃ©dio: 0.045231
Ã‰poca   2000 | Erro mÃ©dio: 0.018456
...
Ã‰poca  45231 | Erro mÃ©dio: 0.003987

âœ“ ConvergÃªncia alcanÃ§ada na Ã©poca 45231
  Erro final: 0.003987
```

### ExecuÃ§Ã£o do RobÃ´
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘   COLLISION AVOIDANCE NEURAL                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Conectando ao robÃ´...
âœ“ RobÃ´ conectado com sucesso!

âœ“ Rede neural inicializada e treinada com sucesso!
âœ“ Sistema em execuÃ§Ã£o!

DecisÃ£o #1 | SaÃ­da NN: 0.6532 | AÃ§Ã£o: FRENTE
DecisÃ£o #2 | SaÃ­da NN: 0.6498 | AÃ§Ã£o: FRENTE
DecisÃ£o #3 | SaÃ­da NN: 0.5321 | AÃ§Ã£o: DIREITA
DecisÃ£o #4 | SaÃ­da NN: 0.6587 | AÃ§Ã£o: FRENTE
...
```

---

## ğŸ“ DemonstraÃ§Ã£o de Conceitos IA

Este projeto demonstra:

### âœ… Aprendizado Supervisionado
- Dataset com pares (entrada, saÃ­da esperada)
- FunÃ§Ã£o de erro comparando prediÃ§Ã£o vs target
- MinimizaÃ§Ã£o iterativa do erro

### âœ… Backpropagation
- CÃ¡lculo de gradientes camada por camada
- Regra da cadeia para derivadas
- AtualizaÃ§Ã£o de pesos proporcional ao erro

### âœ… GeneralizaÃ§Ã£o
- Dataset de treinamento separado de validaÃ§Ã£o
- Rede toma decisÃµes em cenÃ¡rios nÃ£o treinados
- MÃ©tricas de erro em dados nÃ£o vistos

### âœ… OtimizaÃ§Ã£o
- Momentum para evitar mÃ­nimos locais
- Taxa de aprendizado ajustÃ¡vel
- CritÃ©rio de parada baseado em performance

---

## ğŸ“ PersonalizaÃ§Ã£o

### Alterar Arquitetura

Edite `src/train_network.cpp`:

```cpp
// Adicionar mais neurÃ´nios ocultos
network.addHiddenLayer(10, std::make_shared<SigmoidActivation>());

// Adicionar segunda camada oculta
network.addHiddenLayer(5, std::make_shared<SigmoidActivation>());
network.addHiddenLayer(3, std::make_shared<SigmoidActivation>());

// Usar ReLU ao invÃ©s de Sigmoid
network.addHiddenLayer(5, std::make_shared<ReLUActivation>());
```

### Alterar HiperparÃ¢metros

```cpp
// Criar rede com novos valores
NeuralNetwork network(4, 1, 
    0.1,   // learning rate (era 0.3)
    0.95   // momentum (era 0.9)
);
```

### Adicionar PadrÃµes de Treinamento

Edite `createFullTrainingDataset()` em `train_network.cpp`:

```cpp
inputs.push_back({1, 0, 1, 1});  // Novo padrÃ£o
targets.push_back({0.65});        // AÃ§Ã£o: FRENTE
```

---

## ğŸ”— Links Ãšteis

- **ARIA Docs**: http://robots.mobilerobots.com/wiki/ARIA
- **MobileSim**: http://robots.mobilerobots.com/wiki/MobileSim
- **Neural Networks**: http://neuralnetworksanddeeplearning.com/
- **Backpropagation**: https://brilliant.org/wiki/backpropagation/

---

## ğŸ’¡ Dicas para Nota MÃ¡xima

1. **Commits regulares**: FaÃ§a commits pequenos e frequentes
2. **ComentÃ¡rios claros**: Documente o "porquÃª", nÃ£o apenas o "o quÃª"
3. **Testes diversos**: Teste em mÃºltiplos mapas do MobileSim
4. **ApresentaÃ§Ã£o tÃ©cnica**: Explique arquitetura, nÃ£o sÃ³ demonstre
5. **MÃ©tricas**: Mostre grÃ¡ficos de erro, estatÃ­sticas de decisÃ£o
6. **ComparaÃ§Ã£o**: Compare com versÃ£o heurÃ­stica (Colisionavoidancethread.cpp)

---

## ğŸ† BÃ´nus: Algoritmos GenÃ©ticos (+20 pontos)

Para implementar AG e ganhar pontos extras:

### Estrutura Sugerida

```cpp
class GeneticOptimizer {
    // PopulaÃ§Ã£o de redes neurais
    std::vector<NeuralNetwork> population;
    
    // Avaliar fitness de cada indivÃ­duo
    double evaluate(NeuralNetwork& network);
    
    // SeleÃ§Ã£o dos melhores
    void selection();
    
    // Crossover entre pais
    NeuralNetwork crossover(NeuralNetwork& parent1, NeuralNetwork& parent2);
    
    // MutaÃ§Ã£o aleatÃ³ria
    void mutate(NeuralNetwork& network);
};
```

### AplicaÃ§Ãµes

1. **Otimizar hiperparÃ¢metros**: learning rate, momentum
2. **Evoluir arquitetura**: nÃºmero de camadas/neurÃ´nios
3. **Treinar pesos**: alternativa ao backpropagation

---

**Boa sorte na apresentaÃ§Ã£o! ğŸ‰**

*Lembre-se: o cÃ³digo deve rodar perfeitamente na hora!*
